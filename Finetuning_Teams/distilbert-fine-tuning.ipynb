{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning with DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pre-trained model and its respective tokenizer \n",
    "To use different model, simple change the checkpoint to any pre-trained text classification model available in HuggingFace. It should be noted that some model can't be directly fine-tuned using transformers API. [A list of models can be found here](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:10.690370Z",
     "iopub.status.busy": "2023-02-08T08:19:10.689847Z",
     "iopub.status.idle": "2023-02-08T08:19:56.310964Z",
     "shell.execute_reply": "2023-02-08T08:19:56.309870Z",
     "shell.execute_reply.started": "2023-02-08T08:19:10.690263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import  AutoModelForSequenceClassification, AutoTokenizer\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\" # Define which pre-trained model we will be using\n",
    "classifier = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2) # Get the classifier\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint) # Get the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data and preprocess it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:56.313542Z",
     "iopub.status.busy": "2023-02-08T08:19:56.313163Z",
     "iopub.status.idle": "2023-02-08T08:19:56.354888Z",
     "shell.execute_reply": "2023-02-08T08:19:56.353992Z",
     "shell.execute_reply.started": "2023-02-08T08:19:56.313503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the training data\n",
    "train_path = './nlp-getting-started/train.csv'\n",
    "df = pd.read_csv('./nlp-getting-started/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:56.356484Z",
     "iopub.status.busy": "2023-02-08T08:19:56.356122Z",
     "iopub.status.idle": "2023-02-08T08:19:57.294984Z",
     "shell.execute_reply": "2023-02-08T08:19:57.294005Z",
     "shell.execute_reply.started": "2023-02-08T08:19:56.356447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:57.298087Z",
     "iopub.status.busy": "2023-02-08T08:19:57.297680Z",
     "iopub.status.idle": "2023-02-08T08:19:57.321577Z",
     "shell.execute_reply": "2023-02-08T08:19:57.320541Z",
     "shell.execute_reply.started": "2023-02-08T08:19:57.298045Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the data overall\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:57.323481Z",
     "iopub.status.busy": "2023-02-08T08:19:57.323117Z",
     "iopub.status.idle": "2023-02-08T08:19:57.329177Z",
     "shell.execute_reply": "2023-02-08T08:19:57.327930Z",
     "shell.execute_reply.started": "2023-02-08T08:19:57.323444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To make this simple we will drop id, keyword, location and only keep text and target\n",
    "df = df.loc[:,[\"text\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:57.331277Z",
     "iopub.status.busy": "2023-02-08T08:19:57.330928Z",
     "iopub.status.idle": "2023-02-08T08:19:57.718545Z",
     "shell.execute_reply": "2023-02-08T08:19:57.717586Z",
     "shell.execute_reply.started": "2023-02-08T08:19:57.331242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the data into train and evaluation (stratified)\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_eval = train_test_split(df, train_size=0.8,stratify=df.target, random_state=42) # Stratified splitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn pandas dataframe into dataset\n",
    "We will be using Trainer API from HuggingFace for fine-tuning, and it requires data in the form of Dataset. Therefore, we will convert our Pandas DataFrame into DataSet stored in DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:57.720146Z",
     "iopub.status.busy": "2023-02-08T08:19:57.719792Z",
     "iopub.status.idle": "2023-02-08T08:19:58.067895Z",
     "shell.execute_reply": "2023-02-08T08:19:58.066976Z",
     "shell.execute_reply.started": "2023-02-08T08:19:57.720113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "raw_datasets = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"eval\": Dataset.from_pandas(df_eval)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:58.069953Z",
     "iopub.status.busy": "2023-02-08T08:19:58.069273Z",
     "iopub.status.idle": "2023-02-08T08:19:58.078638Z",
     "shell.execute_reply": "2023-02-08T08:19:58.077431Z",
     "shell.execute_reply.started": "2023-02-08T08:19:58.069914Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dict:\n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'target', '__index_level_0__'],\n",
      "        num_rows: 6090\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['text', 'target', '__index_level_0__'],\n",
      "        num_rows: 1523\n",
      "    })\n",
      "})\n",
      "\n",
      "\n",
      "Train's features:\n",
      " {'text': Value(dtype='string', id=None), 'target': Value(dtype='int64', id=None), '__index_level_0__': Value(dtype='int64', id=None)}\n",
      "\n",
      "\n",
      "First row of Train:\n",
      " {'text': 'Sassy city girl country hunk stranded in Smoky Mountain snowstorm #AoMS http://t.co/nkKcTttsD9 #ibooklove #bookboost', 'target': 1, '__index_level_0__': 6234}\n"
     ]
    }
   ],
   "source": [
    "# Check the datasets\n",
    "print(\"Dataset Dict:\\n\", raw_datasets)\n",
    "print(\"\\n\\nTrain's features:\\n\", raw_datasets[\"train\"].features)\n",
    "print(\"\\n\\nFirst row of Train:\\n\", raw_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing\n",
    "Neural network require the input to be in the form of numbers for training to take place. Therefore, we will convert our text into vector of numbers (tokens) by using tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:58.080600Z",
     "iopub.status.busy": "2023-02-08T08:19:58.080118Z",
     "iopub.status.idle": "2023-02-08T08:19:58.795481Z",
     "shell.execute_reply": "2023-02-08T08:19:58.794491Z",
     "shell.execute_reply.started": "2023-02-08T08:19:58.080559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7056ecdaf064b2ea3f134f295f2de71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6090 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90b01781a8649b181395e7e40cdc95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'target', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 6090\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['text', 'target', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1523\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text, and truncate the text if it exceed the tokenizer maximum length. Batched=True to tokenize multiple texts at the same time.\n",
    "tokenized_datasets = raw_datasets.map(lambda dataset: tokenizer(dataset['text'], truncation=True), batched=True)\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:58.799767Z",
     "iopub.status.busy": "2023-02-08T08:19:58.798792Z",
     "iopub.status.idle": "2023-02-08T08:19:58.805266Z",
     "shell.execute_reply": "2023-02-08T08:19:58.804229Z",
     "shell.execute_reply.started": "2023-02-08T08:19:58.799726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Sassy city girl country hunk stranded in Smoky Mountain snowstorm #AoMS http://t.co/nkKcTttsD9 #ibooklove #bookboost', 'target': 1, '__index_level_0__': 6234, 'input_ids': [101, 21871, 6508, 2103, 2611, 2406, 15876, 8950, 15577, 1999, 20629, 3137, 4586, 19718, 1001, 20118, 5244, 8299, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 25930, 2243, 6593, 4779, 16150, 2683, 1001, 21307, 14659, 14301, 2063, 1001, 2338, 5092, 14122, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Check the first row\n",
    "print(tokenized_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to remove text and \\_\\_index_level_0__ as they are not needed for our model fine-tuning. Also we will rename \"target\" to \"labels\", as Trainer API require the target to be named \"labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:58.807720Z",
     "iopub.status.busy": "2023-02-08T08:19:58.807035Z",
     "iopub.status.idle": "2023-02-08T08:19:58.820780Z",
     "shell.execute_reply": "2023-02-08T08:19:58.819663Z",
     "shell.execute_reply.started": "2023-02-08T08:19:58.807683Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 6090\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1523\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"target\", \"labels\")\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We will be using Trainer API from HuggingFace for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-02-08T08:19:58.822736Z",
     "iopub.status.busy": "2023-02-08T08:19:58.822254Z",
     "iopub.status.idle": "2023-02-08T08:20:10.971235Z",
     "shell.execute_reply": "2023-02-08T08:20:10.970060Z",
     "shell.execute_reply.started": "2023-02-08T08:19:58.822692Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip -q install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:20:10.975539Z",
     "iopub.status.busy": "2023-02-08T08:20:10.975216Z",
     "iopub.status.idle": "2023-02-08T08:20:21.168594Z",
     "shell.execute_reply": "2023-02-08T08:20:21.167149Z",
     "shell.execute_reply.started": "2023-02-08T08:20:10.975505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/miniconda3/envs/llm2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# Padding for batch of data that will be fed into model for training\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Training args \n",
    "training_args = TrainingArguments(\"test-trainer\", num_train_epochs=1, evaluation_strategy=\"epoch\", \n",
    "                                  weight_decay=5e-4, save_strategy=\"no\", report_to=\"none\")\n",
    "\n",
    "# Metric for validation error\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\") # F1 and Accuracy\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Define trainer\n",
    "trainer = Trainer(\n",
    "    classifier,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"eval\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:20:21.171170Z",
     "iopub.status.busy": "2023-02-08T08:20:21.169973Z",
     "iopub.status.idle": "2023-02-08T08:20:58.316190Z",
     "shell.execute_reply": "2023-02-08T08:20:58.315155Z",
     "shell.execute_reply.started": "2023-02-08T08:20:21.171126Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf5360a3efd4446a3f3adefa5bfa6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/762 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4859, 'grad_norm': 2.137977361679077, 'learning_rate': 1.7191601049868766e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44354c606b8c4f819c8fc36815034c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3781295716762543, 'eval_accuracy': 0.8483256730137886, 'eval_f1': 0.8132578819725141, 'eval_runtime': 12.428, 'eval_samples_per_second': 122.546, 'eval_steps_per_second': 15.369, 'epoch': 1.0}\n",
      "{'train_runtime': 162.9135, 'train_samples_per_second': 37.382, 'train_steps_per_second': 4.677, 'train_loss': 0.4633314878608924, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=762, training_loss=0.4633314878608924, metrics={'train_runtime': 162.9135, 'train_samples_per_second': 37.382, 'train_steps_per_second': 4.677, 'total_flos': 79399199421768.0, 'train_loss': 0.4633314878608924, 'epoch': 1.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the fine-tuning \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick evaluation using classification metrics\n",
    "We'll be using [sklearn.metrics.classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) to do quick evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-08T08:20:58.319099Z",
     "iopub.status.busy": "2023-02-08T08:20:58.318317Z",
     "iopub.status.idle": "2023-02-08T08:21:02.249065Z",
     "shell.execute_reply": "2023-02-08T08:21:02.247979Z",
     "shell.execute_reply.started": "2023-02-08T08:20:58.319049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ba033cdb6f410ba884cf53dc84a0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.839     0.908     0.872       869\n",
      "           1      0.863     0.769     0.813       654\n",
      "\n",
      "    accuracy                          0.848      1523\n",
      "   macro avg      0.851     0.839     0.843      1523\n",
      "weighted avg      0.849     0.848     0.847      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make prediction on evaluation dataset\n",
    "y_pred = trainer.predict(tokenized_datasets[\"eval\"]).predictions\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "# Get the true labels\n",
    "y_true = tokenized_datasets[\"eval\"][\"labels\"]\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-02-08T08:21:02.251570Z",
     "iopub.status.busy": "2023-02-08T08:21:02.250845Z",
     "iopub.status.idle": "2023-02-08T08:21:07.344758Z",
     "shell.execute_reply": "2023-02-08T08:21:07.343714Z",
     "shell.execute_reply.started": "2023-02-08T08:21:02.251526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14c24f6c30e48b1a25eb9ad1d46f64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3263 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0839ea9ee89240cf8af2d017600ba290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the test data\n",
    "df_test = pd.read_csv(\"./nlp-getting-started/test.csv\")\n",
    "ids = df_test.id # Save ids\n",
    "df_test = df_test.loc[:,[\"text\"]] # Keep only text\n",
    "\n",
    "# Turn the DataFrame into appropriate format\n",
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "test_dataset = test_dataset.map(lambda dataset: tokenizer(dataset['text'], truncation=True), batched=True)\n",
    "test_dataset = test_dataset.remove_columns('text')\n",
    "\n",
    "# Get the prediction\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "# Turn submission into DataFrame and save into CSV files\n",
    "submission = pd.DataFrame({\"id\":ids, \"target\":preds})\n",
    "submission.to_csv(\"outputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
