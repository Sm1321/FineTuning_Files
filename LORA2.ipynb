{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f9dd16d888744361b2ce4cda196f2f91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_803696a243f5475fb561f2bf8d83003b","IPY_MODEL_fda69e4b46c64a158bbb257be578a8ac","IPY_MODEL_129d05fdc6834c26a3e289f43fa9a631"],"layout":"IPY_MODEL_0bd4bfe1a9f641b193d9466e70ad2819"}},"803696a243f5475fb561f2bf8d83003b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3b15831251742a5b69ccf3cacb5482c","placeholder":"â€‹","style":"IPY_MODEL_92e7645d5c624eeaa94005d3fd449ee3","value":"Map:â€‡100%"}},"fda69e4b46c64a158bbb257be578a8ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa941bbe39d04b7b82a2a2be5109a108","max":872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0e900da4bd244ea9192d5ce661669ec","value":872}},"129d05fdc6834c26a3e289f43fa9a631":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46579e38c39b4527afa6434d8b6fdce1","placeholder":"â€‹","style":"IPY_MODEL_fb5ca1637c454b389f46d470481bedaa","value":"â€‡872/872â€‡[00:00&lt;00:00,â€‡3212.65â€‡examples/s]"}},"0bd4bfe1a9f641b193d9466e70ad2819":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b15831251742a5b69ccf3cacb5482c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92e7645d5c624eeaa94005d3fd449ee3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa941bbe39d04b7b82a2a2be5109a108":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0e900da4bd244ea9192d5ce661669ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"46579e38c39b4527afa6434d8b6fdce1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb5ca1637c454b389f46d470481bedaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYOx49xGBO3Q","outputId":"40510f06-8507-46a0-ee82-66f6ecfe5b51","executionInfo":{"status":"ok","timestamp":1743070686925,"user_tz":-330,"elapsed":124790,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/487.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m481.3/487.4 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install datasets -q\n","!pip install transformers -q\n","!pip install peft -q\n","!pip install evaluate -q"]},{"cell_type":"code","source":["from datasets import load_dataset, DatasetDict, Dataset\n","\n","from transformers import (\n","    AutoTokenizer,\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    DataCollatorWithPadding,\n","    TrainingArguments,\n","    Trainer)\n","\n","from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n","import evaluate\n","import torch\n","import numpy as np"],"metadata":{"id":"uqmiGVBGBQbA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The Stanford Sentiment Treebank .The task is to predict the sentiment of a given sentence.\n","dataset = load_dataset(\"glue\", \"sst2\")\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBHeCLydBZZO","outputId":"9b46cfd9-64b8-428a-becb-c8e5254944a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 67349\n","    })\n","    validation: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 872\n","    })\n","    test: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 1821\n","    })\n","})"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["model_checkpoint = 'roberta-base'\n","\n","# define label maps\n","id_label = {0: \"Negative\", 1: \"Positive\"}\n","label_id = {\"Negative\":0, \"Positive\":1}\n","\n","# generate classification model from model_checkpoint\n","Robertamodel = AutoModelForSequenceClassification.from_pretrained(\n","    model_checkpoint, num_labels=2, id2label=id_label, label2id=label_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQxPb8qFBgIg","outputId":"b061b20c-d6b0-4bf4-8107-a83a01c80368"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["Robertamodel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUEa33HkBnJp","outputId":"bb760d1f-d9cd-4668-83f3-113543c2d7d3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# create tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n","\n","# add pad token if none exists\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","    Robertamodel.resize_token_embeddings(len(tokenizer))"],"metadata":{"id":"mRHfd4P3BqbU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create tokenize function\n","def tokenize_function(examples):\n","    # extract text\n","    text = examples[\"sentence\"]\n","\n","    #tokenize and truncate text\n","    tokenizer.truncation_side = \"left\"\n","    tokenized_inputs = tokenizer(\n","        text,\n","        return_tensors=\"np\",\n","        truncation=True,\n","        max_length=512\n","    )\n","\n","    return tokenized_inputs"],"metadata":{"id":"7uMt1mkqBtzv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# tokenize training and validation datasets\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","tokenized_dataset\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303,"referenced_widgets":["f9dd16d888744361b2ce4cda196f2f91","803696a243f5475fb561f2bf8d83003b","fda69e4b46c64a158bbb257be578a8ac","129d05fdc6834c26a3e289f43fa9a631","0bd4bfe1a9f641b193d9466e70ad2819","d3b15831251742a5b69ccf3cacb5482c","92e7645d5c624eeaa94005d3fd449ee3","fa941bbe39d04b7b82a2a2be5109a108","d0e900da4bd244ea9192d5ce661669ec","46579e38c39b4527afa6434d8b6fdce1","fb5ca1637c454b389f46d470481bedaa"]},"id":"2-E5HRDABxgG","outputId":"11349120-422f-497d-c1d6-3fbdd4595823"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/872 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9dd16d888744361b2ce4cda196f2f91"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n","        num_rows: 67349\n","    })\n","    validation: Dataset({\n","        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n","        num_rows: 872\n","    })\n","    test: Dataset({\n","        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n","        num_rows: 1821\n","    })\n","})"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["\n","# create data collator\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"AyKcJcdTB0EI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import accuracy evaluation metric\n","accuracy = evaluate.load(\"accuracy\")"],"metadata":{"id":"wWWPt0GpB6KK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define an evaluation function to pass into trainer later\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=1)\n","\n","    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"],"metadata":{"id":"8MKSeViCB8Ka"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define list of examples\n","text_list = [\"a feel-good picture in the best sense of the term .\",\n","             \"resourceful and ingenious entertainment .\",\n","             \"it 's just incredibly dull .\",\n","             \"the movie 's biggest offense is its complete and utter lack of tension .\",\n","             \"impresses you with its open-endedness and surprises .\",\n","             \"unless you are in dire need of a diesel fix , there is no real reason to see it .\"]\n","\n","print(\"Untrained model predictions:\")\n","print(\"----------------------------\")\n","for text in text_list:\n","    # tokenize text\n","    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n","    # compute logits\n","    logits = Robertamodel(inputs).logits\n","    # convert logits to label\n","    predictions = torch.argmax(logits)\n","\n","    print(text + \" - \" + id_label[predictions.tolist()])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8V5eUe9IB_BV","outputId":"882cbb8f-e397-4f86-9661-898a4520e59a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Untrained model predictions:\n","----------------------------\n","a feel-good picture in the best sense of the term . - Positive\n","resourceful and ingenious entertainment . - Positive\n","it 's just incredibly dull . - Positive\n","the movie 's biggest offense is its complete and utter lack of tension . - Positive\n","impresses you with its open-endedness and surprises . - Positive\n","unless you are in dire need of a diesel fix , there is no real reason to see it . - Positive\n"]}]},{"cell_type":"code","source":["peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n","                        r=4,\n","                        lora_alpha=32,\n","                        lora_dropout=0.01,\n","                        target_modules = ['query'])"],"metadata":{"id":"wbH_iM8GCEOQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["peft_config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9tjEZKdCKoG","outputId":"c60e32fd-fb2c-4aa2-90a9-43e6ebfcb19c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LoraConfig(task_type='SEQ_CLS', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=4, target_modules={'query'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, eva_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["model = get_peft_model(Robertamodel, peft_config)\n","model.print_trainable_parameters()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_qZ2n3A0CMmI","outputId":"ecc0bbdd-45f5-436b-f1ab-2703ac9d0102"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 665,858 || all params: 125,313,028 || trainable%: 0.5314\n"]}]},{"cell_type":"code","source":["# hyperparameters\n","lr = 1e-3\n","batch_size = 16\n","num_epochs = 1"],"metadata":{"id":"1zoYVGlqCPlW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define training arguments\n","training_args = TrainingArguments(\n","    output_dir= model_checkpoint + \"-lora-text-classification\",\n","    learning_rate=lr,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=num_epochs,\n","    weight_decay=0.01,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ig55v9HuCS-w","outputId":"6c46f43c-3d0e-45a4-913b-06d61b59165c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# creater trainer object\n","trainer = Trainer(\n","    model=Robertamodel,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# train model\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217},"id":"UpXpcsnXCVEN","outputId":"951e1238-9995-4993-a549-053f7a426172"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-41-4fd17eab208b>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4210' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4210/4210 05:32, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.221000</td>\n","      <td>0.206079</td>\n","      <td>{'accuracy': 0.9311926605504587}</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"{'accuracy': 0.9311926605504587}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=4210, training_loss=0.27545077398667145, metrics={'train_runtime': 332.4835, 'train_samples_per_second': 202.563, 'train_steps_per_second': 12.662, 'total_flos': 1246924152079512.0, 'train_loss': 0.27545077398667145, 'epoch': 1.0})"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["Robertamodel.to('cpu')\n","\n","print(\"Trained model predictions:\")\n","print(\"--------------------------\")\n","for text in text_list:\n","    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cpu\")\n","\n","    logits = Robertamodel(inputs).logits\n","    predictions = torch.max(logits,1).indices\n","\n","    print(text + \" - \" + id_label[predictions.tolist()[0]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13WdYI_kCYOb","outputId":"47de2fb9-f64b-4f35-e373-54628558dab3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trained model predictions:\n","--------------------------\n","a feel-good picture in the best sense of the term . - Positive\n","resourceful and ingenious entertainment . - Positive\n","it 's just incredibly dull . - Negative\n","the movie 's biggest offense is its complete and utter lack of tension . - Negative\n","impresses you with its open-endedness and surprises . - Positive\n","unless you are in dire need of a diesel fix , there is no real reason to see it . - Negative\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wADH_IxKJI7B"},"execution_count":null,"outputs":[]}]}